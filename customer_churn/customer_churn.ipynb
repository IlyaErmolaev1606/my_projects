{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='0-section'></a>\n",
    "##### I. Разведочный анализ данных:\n",
    "* [1. Изучение файлов с данными, получение общей информации](#1-section)\n",
    "* [2. Исследовательский анализ данных](#2-section)\n",
    "\n",
    "##### II. Подготовка данных к обучению:\n",
    "* [1. Подготовка признаков](#3-section)\n",
    "* [2. Разбиение на выборки](#4-section)\n",
    "\n",
    "##### III. Исследование моделей классификации:\n",
    "* [1. Константная модель](#5-section)\n",
    "* [2. Дисбаланс классов](#6-section)\n",
    "* [3. Баланс классов](#7-section)\n",
    "* [4. Изменение порога](#8-section)\n",
    "* [5. Визуализация метрик](#9-section)\n",
    "\n",
    "##### [IV. Общий вывод](#10-section)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I. Разведочный анализ данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='1-section'></a>\n",
    "### 1. Изучение файлов с данными, получение общей информации"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Вернуться к оглавлению](#0-section)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# загрузим необходимые библиотеки\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, \n",
    "    confusion_matrix, \n",
    "    recall_score, \n",
    "    precision_score, \n",
    "    f1_score, \n",
    "    precision_recall_curve, \n",
    "    roc_auc_score, \n",
    "    roc_curve,\n",
    "    make_scorer\n",
    ")\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, OrdinalEncoder\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.utils import shuffle\n",
    "import seaborn as sns\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from lightgbm import LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# создадим функцию для загрузки датафрейма\n",
    "def get_df(data):\n",
    "    try:\n",
    "        df = pd.read_csv(\n",
    "            \"C:/Users/79090/YandexDisk/from asus/MyStudy/Data Science/Яндекс.Практикум/Самостоятельные проекты/Обучение с учителем/customer_churn/{}.csv\".format(\n",
    "                data\n",
    "            ),\n",
    "            index_col=\"CustomerId\",\n",
    "        )\n",
    "    except:\n",
    "        print(\"Ошибка при чтении файла\")\n",
    "    df.columns = df.columns.str.lower()\n",
    "    print(\"Несколько строк из датафрейма\")\n",
    "    print()\n",
    "    display(df.sample(5))\n",
    "    print()\n",
    "    print(\"Общая информация о датафрейме\")\n",
    "    print()\n",
    "    print(df.info())\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Несколько строк из датафрейма\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rownumber</th>\n",
       "      <th>surname</th>\n",
       "      <th>creditscore</th>\n",
       "      <th>geography</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>tenure</th>\n",
       "      <th>balance</th>\n",
       "      <th>numofproducts</th>\n",
       "      <th>hascrcard</th>\n",
       "      <th>isactivemember</th>\n",
       "      <th>estimatedsalary</th>\n",
       "      <th>exited</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CustomerId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15800814</th>\n",
       "      <td>3511</td>\n",
       "      <td>Palerma</td>\n",
       "      <td>534</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>35</td>\n",
       "      <td>NaN</td>\n",
       "      <td>81951.74</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>115668.53</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15780835</th>\n",
       "      <td>1674</td>\n",
       "      <td>Liang</td>\n",
       "      <td>652</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Female</td>\n",
       "      <td>26</td>\n",
       "      <td>1.0</td>\n",
       "      <td>131908.35</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>179269.79</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15747265</th>\n",
       "      <td>2768</td>\n",
       "      <td>Huang</td>\n",
       "      <td>598</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Female</td>\n",
       "      <td>27</td>\n",
       "      <td>10.0</td>\n",
       "      <td>171283.91</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>84136.12</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15743149</th>\n",
       "      <td>6801</td>\n",
       "      <td>Findlay</td>\n",
       "      <td>711</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>35</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>67508.01</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15637414</th>\n",
       "      <td>741</td>\n",
       "      <td>Gell</td>\n",
       "      <td>618</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>24</td>\n",
       "      <td>7.0</td>\n",
       "      <td>128736.39</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>37147.61</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            rownumber  surname  creditscore geography  gender  age  tenure  \\\n",
       "CustomerId                                                                   \n",
       "15800814         3511  Palerma          534    France    Male   35     NaN   \n",
       "15780835         1674    Liang          652   Germany  Female   26     1.0   \n",
       "15747265         2768    Huang          598   Germany  Female   27    10.0   \n",
       "15743149         6801  Findlay          711    France  Female   35     8.0   \n",
       "15637414          741     Gell          618    France  Female   24     7.0   \n",
       "\n",
       "              balance  numofproducts  hascrcard  isactivemember  \\\n",
       "CustomerId                                                        \n",
       "15800814     81951.74              2          1               0   \n",
       "15780835    131908.35              1          1               1   \n",
       "15747265    171283.91              1          1               1   \n",
       "15743149         0.00              1          1               1   \n",
       "15637414    128736.39              1          0               1   \n",
       "\n",
       "            estimatedsalary  exited  \n",
       "CustomerId                           \n",
       "15800814          115668.53       0  \n",
       "15780835          179269.79       0  \n",
       "15747265           84136.12       0  \n",
       "15743149           67508.01       0  \n",
       "15637414           37147.61       0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Общая информация о датафрейме\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 10000 entries, 15634602 to 15628319\n",
      "Data columns (total 13 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   rownumber        10000 non-null  int64  \n",
      " 1   surname          10000 non-null  object \n",
      " 2   creditscore      10000 non-null  int64  \n",
      " 3   geography        10000 non-null  object \n",
      " 4   gender           10000 non-null  object \n",
      " 5   age              10000 non-null  int64  \n",
      " 6   tenure           9091 non-null   float64\n",
      " 7   balance          10000 non-null  float64\n",
      " 8   numofproducts    10000 non-null  int64  \n",
      " 9   hascrcard        10000 non-null  int64  \n",
      " 10  isactivemember   10000 non-null  int64  \n",
      " 11  estimatedsalary  10000 non-null  float64\n",
      " 12  exited           10000 non-null  int64  \n",
      "dtypes: float64(3), int64(7), object(3)\n",
      "memory usage: 1.1+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "churn = get_df('Churn')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tenure - это количество недвижимости у клиента. Значит \"tenure\" должен иметь тип данных int64. Также в данном столбце присутствуют пропуски.\n",
    "\n",
    "Пропуски могли возникнуть из-за разных причин. Данные могли затереться при копировании/скачивании/форматировании. А может клиенты специально не указали данные о количестве своей недвижимости."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='2-section'></a>\n",
    "### 2. Исследовательский анализ данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# подробнее изучим данные\n",
    "# создадим функцию, возвращающую детальную информацию о данных по столбцу\n",
    "def get_column_info(data, column):\n",
    "    print('{: ^}'.format(\"_\" * (len(\"Числовое описание данных столбца\") + len(column) + 1)))\n",
    "    print()\n",
    "    print('Числовое описание данных столбца \"{}\"'.format(column))\n",
    "    print()\n",
    "    if data[column].isnull().sum() > 0:\n",
    "        print('Количество пропусков: {}'.format(data[column].isnull().sum()))\n",
    "    else:\n",
    "        print('В столбце нет пропусков')\n",
    "    print()\n",
    "    try:\n",
    "        print(\n",
    "            \"Коэффициент корреляции Пирсона с целевым признаком: {:.2f}\".format(\n",
    "                data[column].corr(\n",
    "                    data[\"exited\"]\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "    except:\n",
    "        pass\n",
    "    print()\n",
    "    print(data[column].describe())\n",
    "    print()\n",
    "    # выведем max, min, наиболее и наименее частотные значения столбца\n",
    "    # если уникальных значений больше пяти\n",
    "    if len(data[column].unique()) > 5:\n",
    "        if data[column].value_counts().min() != data[column].value_counts().max():\n",
    "            print('Наиболее частотные значения столбца')\n",
    "            print()\n",
    "            print(data[column].value_counts().head())\n",
    "            print()\n",
    "            print('Наименее частотные значения столбца')\n",
    "            print()\n",
    "            print(data[column].value_counts().tail())\n",
    "            print()\n",
    "        print()\n",
    "        if data[column].dtype in ['int64', 'float64']:\n",
    "            if data.groupby(column)[column].count().max() != data.groupby(column)[column].count().min():\n",
    "                print('Максимальные значения столбца')\n",
    "                print()\n",
    "                print(data.groupby(column)[column].count()[::-1].head())\n",
    "                print()\n",
    "                print('Минимальные значения столбца')\n",
    "                print()\n",
    "                print(data.groupby(column)[column].count().head()[::-1])\n",
    "                print()\n",
    "            print(\"Диаграмма размаха столбца\", column)\n",
    "            sns.boxplot(x=data[column])\n",
    "            plt.show()\n",
    "            print()\n",
    "            print(\"Гистограмма для столбца\", column)\n",
    "            ax = sns.distplot(data[column])\n",
    "            plt.show()\n",
    "    else:\n",
    "        print()\n",
    "        print('Распределение данных столбца \"{}\"'.format(column))\n",
    "        print()\n",
    "        print(data[column].value_counts())\n",
    "        data[column].value_counts().plot(kind='pie', subplots=True, figsize=(9,6), autopct='%1.1f%%')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# создадим функцию для вывода информации о всех столбцах датафрейма\n",
    "def get_all_columns_info(data):\n",
    "    for column in data.columns:\n",
    "        get_column_info(data, column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "get_all_columns_info(churn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Кредитный рейтинг имеет нормальное распределение. Заметим всплеск на значении 850. Это максимально возможное значение рейтинга. То есть 233 человека являются максимально добропорядочными с точки зрения кредитного доверия.\n",
    "\n",
    "Данные по возрасту немного скошены вправо. Самому юному клиенту 18 лет, самому возрастному - 92 года. Возраст большинства клиентов находится в диапазоне 31 - 44 лет.\n",
    "\n",
    "3617 человек имеют баланс равный 0. В остальных случаях распределение выглядит нормальным."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на тех, кто отказался от услуг компании"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left = churn.query('exited == 1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_all_columns_info(left) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# посмотрим на текущих клиентов\n",
    "current = churn.query('exited == 0')\n",
    "get_all_columns_info(current) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сравнивая полученную информацию об ушедших клиентах, можно сказать об основных изменениях (в скобках представлены значения для текущих клиентов):\n",
    "- средний возраст ушедших клиентов - `45`лет (`37.4`);\n",
    "- средний баланс на карте у ушедших клиентов - `91108` (`72745`);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# построим матрицу корреляции всего df\n",
    "churn.corr().style.background_gradient(cmap='PuBuGn')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Присутствует слабая прямая корреляция между возрастом и фактом ухода (0.285)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вывод"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Изучили общую информацию о датафрейме:\n",
    " - названия столбцов привели к нижнему регистру;\n",
    " - в столбце с количеством недвижимости \"tenure\" присутствуют пропуски;\n",
    "\n",
    "Также был проведён исследовательский анализ данных. В результате чего выяснилось, что средний возраст ушедших клиентов `45`лет, а действующих клиентов - `37.4`; средний баланс на карте у ушедших клиентов - `91108`, а у текущих клиентов - `72745`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II. Подготовка данных к обучению"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='3-section'></a>\n",
    "### 1. Подготовка признаков"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Вернуться к оглавлению](#0-section)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# заменим пропуски в столбце tenure на характерные\n",
    "# для этого разделим значения кредитного рейтинга и возраста клиентов на группы\n",
    "def get_group_creditscore(row):\n",
    "    creditscore = row['creditscore']\n",
    "    return creditscore // 50\n",
    "def get_group_age(row):\n",
    "    age = row['age']\n",
    "    return age // 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# создадим копию df\n",
    "churn_up = churn.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# заполним значения с помощью функции apply(), get_group_creditscore(), get_group_age()\n",
    "churn_up['creditscore_level'] = churn_up.apply(get_group_creditscore, axis=1)\n",
    "churn_up['age_level'] = churn_up.apply(get_group_age, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# создадим функцию, которая по заданному df и столбцу, создавала бы сводную таблицу, в которой для каждой возрастной категории и \n",
    "# категории кредитного рейтинга считала бы среднее значение выбранного столбца\n",
    "# и затем для каждого соответствия категорий возраста и кредитного рейтинга исходного df заполняла бы пропуск в данном \n",
    "# столбце из этой сводной таблицы\n",
    "def fill_with_pivot_table(data, column):\n",
    "    # создадим сводную таблицу, в которой для каждой марки и модели автомобиля считается среднее значение столбца column\n",
    "    pivot_table = data.pivot_table(index=['creditscore_level', 'age_level'], values=column).astype(int)\n",
    "    # создадим df, который является срезом data, состоящим из пропусков в столбце column\n",
    "    df_nan = data.loc[data[column].isnull()]\n",
    "    def change_values(row):\n",
    "        creditscore_level = row['creditscore_level']\n",
    "        age_level = row['age_level']\n",
    "        # создадим конструкцию try/except на случай, если в pivot_table не найдется значения по двум категориям\n",
    "        try:\n",
    "            value = pivot_table.loc[(creditscore_level, age_level),:]\n",
    "        except:\n",
    "            value = np.nan\n",
    "        return value    \n",
    "    # заполним пропуски в df_nan с помощью функции change_values() и apply()  \n",
    "    df_nan = df_nan.copy()\n",
    "    df_nan[column] = df_nan.apply(change_values, axis=1)\n",
    "    # теперь надо заменить значения в data из df_nan\n",
    "    for i in df_nan.index:\n",
    "        if i in data.index:\n",
    "            data.loc[i,column] = df_nan.loc[i,column]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# применим функцию fill_with_pivot_table()\n",
    "fill_with_pivot_table(churn_up, 'tenure')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# посмотрим на пропуски\n",
    "churn_up.loc[churn_up['tenure'].isnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В данных остался только 1 пропуск. Мужчина 92 лет. Получим медианное значение для категории creditscore_level = 15 и возрастом не менее 70 лет."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "round(churn_up.query('creditscore_level == 15 & age_level > 6')['tenure'].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# заменим пропуск на данное значение\n",
    "churn_up = churn_up.fillna(\n",
    "    round(churn_up.query(\"creditscore_level == 15 & age_level > 6\")[\"tenure\"].median())\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# изменим тип данных в \"tenure\" на целочисленный\n",
    "churn_up['tenure'] = churn_up['tenure'].astype('int64')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Но вначале воспользуемся библиотекой LOFO."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install lofo-importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.autonotebook import tqdm\n",
    "from lofo import LOFOImportance, Dataset, plot_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target=\"exited\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset(\n",
    "    df=churn_up,\n",
    "    target=\"exited\",\n",
    "    features=[col for col in churn_up.columns if col != target],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# определим схему кроссвалидации и метрику\n",
    "lofo_imp = LOFOImportance(dataset, cv=5, scoring=\"f1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# получить среднее значение и стандартное отклонение значений\n",
    "importance_df = lofo_imp.get_importance()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# построим график важности признаков\n",
    "plot_importance(importance_df, figsize=(12, 20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# оставим значимые признаки\n",
    "final = churn_up.drop([\n",
    "    'age_level',\n",
    "    'gender',\n",
    "    'creditscore_level',\n",
    "    'surname',\n",
    "], axis=1).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# выделим столбцы с числовыми и категориальными признаками\n",
    "numeric = [col for col in final.columns if final[col].dtype in ['int64', 'float64'] and col != target]\n",
    "category = [col for col in final.columns if final[col].dtype in ['object']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='4-section'></a>\n",
    "### 2. Разбиение на выборки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Вернуться к оглавлению](#0-section)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Необходимо преобразовать категориальные признаки в численные. В этом нам поможет One-Hot Encoding (OHE) и OrdinalEncoder. Учтём также, что факт ухода клиента не зависит от его фамилии, поэтому не будем работать с данным категориальным признаком. Также, как и признаки \"rownumber\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dummies(data):\n",
    "    data = pd.get_dummies(data, drop_first=True)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# воспользуемся функцией get_dummies()\n",
    "final_ohe = dummies(final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# используем OrdinalEncoder() для преобразования категориальных признаков в числовые\n",
    "final_oe = final.copy()\n",
    "enc = OrdinalEncoder()\n",
    "enc.fit(final[category])\n",
    "final_oe[category] = pd.DataFrame(enc.transform(final[category]), columns=final[category].columns, index=final[category].index)\n",
    "final_oe.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Все оставшиеся признаки значимы. Но в данных есть значения предполагаемой зарплаты - порядка сотен тысяч, а есть кредитный рейтинг - порядка нескольких сотен. Необходимо масштабировать признаки. Воспользуемся стандартизацией данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features_target(data):\n",
    "    features = data.drop('exited', axis=1)\n",
    "    target = data['exited']\n",
    "    features_train, features_test, target_train, target_test = train_test_split(\n",
    "        features, target, test_size=0.2, random_state=42, stratify=target)\n",
    "    print(features_train.shape, features_test.shape, target_train.shape, target_test.shape)\n",
    "    return features_train, features_test, target_train, target_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "fea_train_ohe, fea_test_ohe, tar_train_ohe, tar_test_ohe = get_features_target(final_ohe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "fea_train_oe, fea_test_oe, tar_train_oe, tar_test_oe = get_features_target(final_oe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_scaler(features_train, features_test):\n",
    "    # создадим объект структуры данных StandardScaler\n",
    "    scaler = StandardScaler()\n",
    "    # сделаем копии выборок\n",
    "    features_train = features_train.copy()\n",
    "    features_test = features_test.copy()\n",
    "    # настроим на обучающей выборке\n",
    "    scaler.fit(features_train.loc[:, numeric])\n",
    "    # преобразуем обучающую и валидационную выборки\n",
    "    features_train.loc[:, numeric] = scaler.transform(features_train.loc[:, numeric])\n",
    "    features_test.loc[:, numeric] = scaler.transform(features_test.loc[:, numeric])\n",
    "    display(features_train.head(3))\n",
    "    return features_train, features_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fea_train_ohe, fea_test_ohe = get_scaler(fea_train_ohe, fea_test_ohe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fea_train_oe, fea_test_oe = get_scaler(fea_train_oe, fea_test_oe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вывод"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На данном этапе работы мы занимались обработкой и подготовкой данных.\n",
    "\n",
    "В результате чего\n",
    "- добавили два столца - категории кредитного рейтинга и возраста. На их основании заменили пропуски в столбце \"tenure\";\n",
    "- построили график важности признаков и оставили наиболее значимые признаки;\n",
    "- выделили столбцы с числовыми и категориальными признаками;\n",
    "- преобразовали категориальные признаки в числовые с помощью OHE и OrdinalEncoder;\n",
    "- разбили данные на обучающую и тестовую выборки;\n",
    "- масштабировали числовые признаки.\n",
    "\n",
    "Данные подготовлены к дальнейшему обучению."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III. Исследование моделей классификации"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В данной работе будут исследованы три классические модели задачи классификации и три модели градентного бустинга: \n",
    "- логистическая регрессия;\n",
    "- решающее дерево;\n",
    "- случайный лес;\n",
    "- LGBMClassifier;\n",
    "- XGBClassifier;\n",
    "- CatBoostClassifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#посмотрим, насколько часто клиенты уходят из банка\n",
    "final['exited'].value_counts(normalize=True).plot(kind='bar', title='Доля клиентов, ушедших из банка')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Заметим, что клиентов, оставшихся в банке, примерно в 4 раза больше ушедших клиентов. Достаточно большая разница."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_scorer = make_scorer(f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# напишем функцию для моделей с использованием GridSearchCV()\n",
    "def get_best_model(model, parameters, x_train, x_test, y_train, y_test):\n",
    "    clf = GridSearchCV(estimator=model, param_grid=parameters, cv=5, verbose=1, n_jobs=-1, scoring=f1_scorer)\n",
    "    clf.fit(x_train, y_train)\n",
    "    best_model = clf.best_estimator_\n",
    "    best_model.fit(x_train, y_train)\n",
    "    pred_train = best_model.predict(x_train)\n",
    "    pred_test = best_model.predict(x_test)\n",
    "    print('Лучшие параметры модели:', clf.best_params_)\n",
    "    print()\n",
    "    print('Матрица ошибок:')\n",
    "    sns.heatmap(confusion_matrix(y_train, pred_train), annot=True, fmt=\"d\")\n",
    "    plt.show()\n",
    "    print()\n",
    "    # вычислим значение полноты, точности, F1-меры модели\n",
    "    accuracy_train = accuracy_score(y_train, pred_train)\n",
    "    recall_train = recall_score(y_train, pred_train)\n",
    "    precision_train = precision_score(y_train, pred_train)\n",
    "    f1_train = f1_score(y_train, pred_train)\n",
    "    accuracy_test = accuracy_score(y_test, pred_test)\n",
    "    recall_test = recall_score(y_test, pred_test)\n",
    "    precision_test = precision_score(y_test, pred_test)\n",
    "    f1_test = f1_score(y_test, pred_test)\n",
    "    # вычислим значение AUC-ROC\n",
    "    probabilities_train = best_model.predict_proba(x_train)\n",
    "    probabilities_one_train = probabilities_train[:, 1]\n",
    "    roc_auc_train = roc_auc_score(y_train, probabilities_one_train)\n",
    "    probabilities_test = best_model.predict_proba(x_test)\n",
    "    probabilities_one_test = probabilities_test[:, 1]\n",
    "    roc_auc_test = roc_auc_score(y_test, probabilities_one_test)\n",
    "    print('\"ROC-AUC\" на обучающей выборке: {}'.format(roc_auc_train))\n",
    "    print('\"ROC-AUC\" на тестовой выборке: {}'.format(roc_auc_test))\n",
    "    df = pd.DataFrame(data=[[accuracy_train,accuracy_test], \n",
    "                            [recall_train,recall_test], \n",
    "                            [precision_train,precision_test], \n",
    "                            [f1_train,f1_test], \n",
    "                            [roc_auc_train,roc_auc_test]], \n",
    "                      index=['accuracy', 'recall', 'precision', 'f1', 'roc_auc'], \n",
    "                      columns=['Метрики на обучающей выборке','Метрики на тестовой выборке'])\n",
    "    display(df)\n",
    "    return best_model, df, probabilities_one_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='5-section'></a>\n",
    "### 1. Константная модель"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Вернуться к оглавлению](#0-section)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# определим точность предсказания константной модели\n",
    "def dummy_model(x_train, x_test, y_train, y_test, constant):\n",
    "    # константная модель, всегда предсказывающая значение по выбранной стратегии\n",
    "    dummy = DummyClassifier(strategy='constant', constant=constant, random_state=42)\n",
    "    dummy.fit(x_train, y_train)\n",
    "    pred_test = dummy.predict(x_test)\n",
    "    # вычислим значение точности, полноты, F1-меры и AUC-ROC константной модели\n",
    "    accuracy = accuracy_score(y_test, pred_test)\n",
    "    recall = recall_score(y_test, pred_test)\n",
    "    precision = precision_score(y_test, pred_test)\n",
    "    f1 = f1_score(y_test, pred_test)\n",
    "    dummy_probabilities_test = dummy.predict_proba(x_test)\n",
    "    dummy_probabilities_one_test = dummy_probabilities_test[:, 1]\n",
    "    auc_roc = roc_auc_score(y_test, dummy_probabilities_one_test)\n",
    "    df = pd.DataFrame(data=[[accuracy], \n",
    "                            [recall], \n",
    "                            [precision], \n",
    "                            [f1], \n",
    "                            [auc_roc]], \n",
    "                      index=['accuracy', 'recall', 'precision', 'f1', 'roc_auc'], \n",
    "                      columns=['Значения метрик'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_0 = dummy_model(fea_train_ohe, fea_test_ohe, tar_train_ohe, tar_test_ohe, 0)\n",
    "dummy_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_1 = dummy_model(fea_train_ohe, fea_test_ohe, tar_train_ohe, tar_test_ohe, 1)\n",
    "dummy_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Лучший результат метрики \"ROC-AUC\" константной модели - `0.5`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='6-section'></a>\n",
    "### 2. Дисбаланс классов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Вернуться к оглавлению](#0-section)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# создадим словарь для логистической регрессии\n",
    "param_log_reg = {\n",
    "    \"C\": list(range(1, 100, 1)),\n",
    "    \"random_state\": [42],\n",
    "}\n",
    "\n",
    "def log_reg(features_train, features_test, target_train, target_test, class_weight):\n",
    "    # используем функцию get_best_model()\n",
    "    lr_model, lr_df, lr_proba = get_best_model(\n",
    "        LogisticRegression(solver=\"liblinear\", class_weight=class_weight),\n",
    "        param_log_reg,\n",
    "        features_train,\n",
    "        features_test,\n",
    "        target_train,\n",
    "        target_test,\n",
    "    )\n",
    "    return lr_model, lr_df, lr_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "lr_model_disb, lr_df_disb, lr_proba_disb = log_reg(\n",
    "    fea_train_ohe,\n",
    "    fea_test_ohe, \n",
    "    tar_train_ohe,\n",
    "    tar_test_ohe,\n",
    "    None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# создадим словарь для решающего дерева\n",
    "param_dec_tree = {\n",
    "    'max_depth'         : list(range(1, 20, 1)),\n",
    "    'min_samples_split' : list(range(2, 5, 1)),\n",
    "    'min_samples_leaf'  : list(range(1, 5, 1)), \n",
    "    'random_state'      : [42],\n",
    "}\n",
    "# используем функцию get_best_model()\n",
    "def dec_tree(features_train, features_test, target_train, target_test, class_weight):\n",
    "    # используем функцию get_best_model()\n",
    "    dt_model, dt_df, dt_proba = get_best_model(\n",
    "        DecisionTreeClassifier(class_weight=class_weight),\n",
    "        param_dec_tree,\n",
    "        features_train,\n",
    "        features_test,\n",
    "        target_train,\n",
    "        target_test,\n",
    "    )\n",
    "    return dt_model, dt_df, dt_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "dt_model_disb, dt_df_disb, dt_proba_disb = dec_tree(\n",
    "    fea_train_oe,\n",
    "    fea_test_oe, \n",
    "    tar_train_oe,\n",
    "    tar_test_oe,\n",
    "    None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# создадим словарь для случайного леса\n",
    "param_rand_for = {\n",
    "    'n_estimators'      : list(range(1, 120, 5)),\n",
    "    'max_depth'         : list(range(1, 15, 1)), \n",
    "    'random_state'      : [42],\n",
    "}\n",
    "# используем функцию get_best_model()\n",
    "def rand_for(features_train, features_test, target_train, target_test, class_weight):\n",
    "    # используем функцию get_best_model()\n",
    "    rand_for_model, rf_df, rf_proba = get_best_model(\n",
    "        RandomForestClassifier(class_weight=class_weight),\n",
    "        param_rand_for,\n",
    "        features_train,\n",
    "        features_test,\n",
    "        target_train,\n",
    "        target_test,\n",
    "    )\n",
    "    return rand_for_model, rf_df, rf_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "rf_model_disb, rf_df_disb, rf_proba_disb = rand_for(\n",
    "    fea_train_oe,\n",
    "    fea_test_oe, \n",
    "    tar_train_oe,\n",
    "    tar_test_oe,\n",
    "    None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# создадим словарь для xgboost\n",
    "param_xgb = {\n",
    "    \"n_estimators\": list(range(40, 120, 5)),\n",
    "    \"max_depth\": list(range(1, 5, 1)),\n",
    "    'objective':['binary:logistic'],\n",
    "    'gamma':[0,0.2],\n",
    "    'eta':[0.1,0.07,0.06],\n",
    "}\n",
    "# используем функцию get_best_model()\n",
    "def xgb(features_train, features_test, target_train, target_test, class_weight):\n",
    "    xgb_model, xgb_df, xgb_proba = get_best_model(\n",
    "        XGBClassifier(use_label_encoder=False, verbosity = 0, random_state=42, silent=True, class_weight=class_weight),\n",
    "        param_xgb,\n",
    "        features_train,\n",
    "        features_test,\n",
    "        target_train,\n",
    "        target_test,\n",
    "    )\n",
    "    return xgb_model, xgb_df, xgb_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "xgb_model_disb, xgb_df_disb, xgb_proba_disb = xgb(\n",
    "    fea_train_oe,\n",
    "    fea_test_oe, \n",
    "    tar_train_oe,\n",
    "    tar_test_oe,\n",
    "    None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# создадим словарь для lightgbm\n",
    "param_lgb = {\n",
    "    \"n_estimators\": list(range(72, 150, 3)),\n",
    "    \"max_depth\": list(range(1, 20, 1)),\n",
    "}\n",
    "# используем функцию get_best_model()\n",
    "def lgb(features_train, features_test, target_train, target_test, class_weight):\n",
    "    lgb_model, lgb_df, lgb_proba = get_best_model(\n",
    "        LGBMClassifier(\n",
    "            boosting_type=\"gbdt\",\n",
    "            verbosity=0,\n",
    "            objective=\"binary\",\n",
    "            feature_fraction=0.9,\n",
    "            random_state=42,\n",
    "            silent=True,\n",
    "            class_weight=class_weight,\n",
    "        ),\n",
    "        param_lgb,\n",
    "        features_train,\n",
    "        features_test,\n",
    "        target_train,\n",
    "        target_test,\n",
    "    )\n",
    "    return lgb_model, lgb_df, lgb_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "lgb_model_disb, lgb_df_disb, lgb_proba_disb = lgb(\n",
    "    fea_train_oe,\n",
    "    fea_test_oe, \n",
    "    tar_train_oe,\n",
    "    tar_test_oe,\n",
    "    None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# создадим словарь для catboost\n",
    "param_ctb = {\n",
    "    \"depth\": list(range(1, 16, 1)),\n",
    "}\n",
    "# используем функцию get_best_model()\n",
    "def ctb(features_train, features_test, target_train, target_test):\n",
    "    ctb_model, ctb_df, ctb_proba = get_best_model(\n",
    "        CatBoostClassifier(learning_rate=0.05, \n",
    "                           iterations=40, \n",
    "                           verbose=False),\n",
    "        param_ctb,\n",
    "        features_train,\n",
    "        features_test,\n",
    "        target_train,\n",
    "        target_test,\n",
    "    )\n",
    "    return ctb_model, ctb_df, ctb_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "ctb_model_disb, ctb_df_disb, ctb_proba_disb = ctb(\n",
    "    fea_train_oe,\n",
    "    fea_test_oe, \n",
    "    tar_train_oe,\n",
    "    tar_test_oe\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='7-section'></a>\n",
    "### 3. Баланс классов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Вернуться к оглавлению](#0-section)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подготовим данные, чтобы они стали более сбалансированными."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## используем технику upsampling увеличения выборки\n",
    "def upsample(features, target):\n",
    "    # разделим обучающую выборку на отрицательные и положительные объекты\n",
    "    features_zeros = features[target == 0]\n",
    "    features_ones = features[target == 1]\n",
    "    target_zeros = target[target == 0]\n",
    "    target_ones = target[target == 1]\n",
    "    # скопируем несколько раз положительные объекты, создаем новую обучающую выборку\n",
    "    features_upsampled = pd.concat([features_zeros] + [features_ones] * round(len(features_zeros) / len(features_ones)))\n",
    "    target_upsampled = pd.concat([target_zeros] + [target_ones] * round(len(features_zeros) / len(features_ones)))\n",
    "    # перемешиваем данные\n",
    "    features_upsampled, target_upsampled = shuffle(\n",
    "        features_upsampled, target_upsampled, random_state=42)\n",
    "    \n",
    "    return features_upsampled, target_upsampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## получили новую обучающую выборку\n",
    "fea_train_up_ohe, tar_train_up_ohe = upsample(fea_train_ohe, tar_train_ohe)\n",
    "fea_train_up_oe, tar_train_up_oe = upsample(fea_train_oe, tar_train_oe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "lr_model_up, lr_df_up, lr_proba_up = log_reg(\n",
    "    fea_train_up_ohe,\n",
    "    fea_test_ohe, \n",
    "    tar_train_up_ohe,\n",
    "    tar_test_ohe,\n",
    "    None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_model_bal, lr_df_bal, lr_proba_bal = log_reg(\n",
    "    fea_train_up_ohe,\n",
    "    fea_test_ohe, \n",
    "    tar_train_up_ohe,\n",
    "    tar_test_ohe,\n",
    "    'balanced',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "dt_model_up, dt_df_up, dt_proba_up = dec_tree(\n",
    "    fea_train_up_oe,\n",
    "    fea_test_oe, \n",
    "    tar_train_up_oe,\n",
    "    tar_test_oe,\n",
    "    None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "dt_model_bal, dt_df_bal, dt_proba_bal = dec_tree(\n",
    "    fea_train_up_oe,\n",
    "    fea_test_oe, \n",
    "    tar_train_up_oe,\n",
    "    tar_test_oe,\n",
    "    'balanced'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "rf_model_up, rf_df_up, rf_proba_up = rand_for(\n",
    "    fea_train_up_oe,\n",
    "    fea_test_oe, \n",
    "    tar_train_up_oe,\n",
    "    tar_test_oe,\n",
    "    None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "rf_model_bal, rf_df_bal, rf_proba_bal = rand_for(\n",
    "    fea_train_up_oe,\n",
    "    fea_test_oe, \n",
    "    tar_train_up_oe,\n",
    "    tar_test_oe,\n",
    "    'balanced'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "xgb_model_up, xgb_df_up, xgb_proba_up = xgb(\n",
    "    fea_train_up_oe,\n",
    "    fea_test_oe, \n",
    "    tar_train_up_oe,\n",
    "    tar_test_oe,\n",
    "    None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "xgb_model_bal, xgb_df_bal, xgb_proba_bal = xgb(\n",
    "    fea_train_up_oe,\n",
    "    fea_test_oe, \n",
    "    tar_train_up_oe,\n",
    "    tar_test_oe,\n",
    "    'balanced'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "lgb_model_up, lgb_df_up, lgb_proba_up = lgb(\n",
    "    fea_train_up_oe,\n",
    "    fea_test_oe, \n",
    "    tar_train_up_oe,\n",
    "    tar_test_oe,\n",
    "    None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "lgb_model_bal, lgb_df_bal, lgb_proba_bal = lgb(\n",
    "    fea_train_up_oe,\n",
    "    fea_test_oe, \n",
    "    tar_train_up_oe,\n",
    "    tar_test_oe,\n",
    "    'balanced'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "ctb_model_up, ctb_df_up, ctb_proba_up = ctb(\n",
    "    fea_train_up_oe,\n",
    "    fea_test_oe, \n",
    "    tar_train_up_oe,\n",
    "    tar_test_oe\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Лучшее значение F1-меры оказалось равным `0.6455`. Это значение удалось достичь для модели LightGBM с помощью техники upsampling. Техника downsampling для LightGBM дала результат `0.6204` и для CatBoost - `0.6186`.\n",
    "\n",
    "Случайный лес показал результат немного хуже - `0.6213`.\n",
    "\n",
    "Решающее дерево и логистическая регрессия показали себя хуже: `0.5952` и `0.5873` соответственно."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='8-section'></a>\n",
    "### 4. Изменение порога"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Вернуться к оглавлению](#0-section)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "По умолчанию значение порога равно 0.5. Что, если мы поменяем это значение, может быть наша модель станет лучше?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# напишем функцию, которая принимает на вход модель и возвращает значение f1-меры и значение порога. \n",
    "def get_f1_threshold(model, proba_one_test):\n",
    "    # переберем значения порогов от 0 до 1 с шагом в 0.01\n",
    "    best_f1 = 0\n",
    "    for threshold in np.arange(0, 1, 0.01):\n",
    "        predicted_test = proba_one_test > threshold\n",
    "        f1 = f1_score(tar_test_ohe, predicted_test)\n",
    "        if f1 > best_f1:\n",
    "            best_f1 = f1\n",
    "            best_threshold = threshold\n",
    "    print('Лучшее значение F1-меры - {:.4f} - достигается при значении порога - {:.2f}'.format(best_f1, best_threshold))\n",
    "    predicted_test = proba_one_test > best_threshold\n",
    "    return best_f1, best_threshold, predicted_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    f1_xgb_bal,\n",
    "    threshold_xgb_bal,\n",
    "    predicted_test_xgb_bal,\n",
    ") = get_f1_threshold(rf_model_disb, rf_proba_disb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    f1_xgb_bal,\n",
    "    threshold_xgb_bal,\n",
    "    predicted_test_xgb_bal,\n",
    ") = get_f1_threshold(xgb_model_bal, xgb_proba_bal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    f1_xgb_bal,\n",
    "    threshold_xgb_bal,\n",
    "    predicted_test_xgb_bal,\n",
    ") = get_f1_threshold(xgb_model_bal, xgb_proba_bal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    f1_xgb_bal,\n",
    "    threshold_xgb_bal,\n",
    "    predicted_test_xgb_bal,\n",
    ") = get_f1_threshold(xgb_model_bal, xgb_proba_bal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    f1_xgb_bal,\n",
    "    threshold_xgb_bal,\n",
    "    predicted_test_xgb_bal,\n",
    ") = get_f1_threshold(xgb_model_bal, xgb_proba_bal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Таким образом, нам удалось достичь значения F1-меры `0.6586` на валидационной выборке при значении порога - `0.59` для модели CatBoost с помощью техники downsampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ctb_down['Значения метрик_threshold'] = [accuracy_score(target_valid, predicted_valid_ctb_down),\n",
    "                                           recall_score(target_valid, predicted_valid_ctb_down),\n",
    "                                           precision_score(target_valid, predicted_valid_ctb_down),\n",
    "                                           f1_score(target_valid, predicted_valid_ctb_down),\n",
    "                                           roc_auc_score(target_valid, probabilities_one_valid_ctb_down)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='9-section'></a>\n",
    "### 5. Визуализация метрик"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Вернуться к оглавлению](#0-section)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#построим PR-кривую\n",
    "precision, recall, thresholds = precision_recall_curve(target_valid, probabilities_valid_ctb_down[:, 1])\n",
    "\n",
    "plt.figure(figsize=(9, 6))\n",
    "plt.step(recall, precision, where='post')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.title('Кривая Precision-Recall')\n",
    "plt.scatter(df_ctb_down.loc['recall', 'Значения метрик_threshold'], df_ctb_down.loc['precision', 'Значения метрик_threshold'], \\\n",
    "            color='black', s=40)\n",
    "plt.annotate('Max F1-score', xy=(df_ctb_down.loc['recall', 'Значения метрик_threshold'], \\\n",
    "                                 df_ctb_down.loc['precision', 'Значения метрик_threshold']), xytext=(0.8, 0.8),\n",
    "             arrowprops=dict(facecolor='black', shrink=0.05)\n",
    "             )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# построим ROC-кривую\n",
    "# для сравнения на графике представлена ROC-кривая случайной модели\n",
    "fpr_lgb, tpr_lgb, thresholds_lgb = roc_curve(\n",
    "    tar_test_oe, lgb_proba_bal)\n",
    "fpr_xgb, tpr_xgb, thresholds_xgb = roc_curve(\n",
    "    tar_test_oe, xgb_proba_bal)\n",
    "fpr_ctb, tpr_ctb, thresholds_ctb = roc_curve(\n",
    "    tar_test_oe, ctb_proba_disb)\n",
    "fpr_rf, tpr_rf, thresholds_rf = roc_curve(\n",
    "    tar_test_oe, rf_proba_disb)\n",
    "fpr_lr, tpr_lr, thresholds_lr = roc_curve(\n",
    "    tar_test_oe, lr_proba_disb)\n",
    "fpr_dt, tpr_dt, thresholds_dt = roc_curve(\n",
    "    tar_test_oe, dt_proba_disb)\n",
    "plt.figure(figsize=(13, 13))\n",
    "plt.plot(fpr_lgb, tpr_lgb, label='LightGBM')\n",
    "plt.plot(fpr_xgb, tpr_xgb, label='XGBoost')\n",
    "plt.plot(fpr_ctb, tpr_ctb, label='CatBoost')\n",
    "plt.plot(fpr_rf, tpr_rf, label='Случайный лес')\n",
    "plt.plot(fpr_lr, tpr_lr, label='Логистическая регрессия')\n",
    "plt.plot(fpr_dt, tpr_dt, label='Решающее дерево')\n",
    "plt.legend()\n",
    "plt.plot([0, 1], [0, 1], linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC-кривая')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вывод"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В результате исследования моделей классификации было выявлено, что лучшая модель для данной задачи - CatBoost. Максимальное значение F1-меры такой модели равно `0.6586`. Оно получается после изменения порога до значения `0.59`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='9-section'></a>\n",
    "## V. Общий вывод"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В данной работе была получена модель, которая прогнозирует, уйдёт клиент из банка в ближайшее время или нет.\n",
    "\n",
    "Данная модель - это модель градиентного бустинга CatBoost, которая успешно предсказывает результат примерно в `84.5%` случаев.\n",
    "\n",
    "Также были исследованы модели логистической регрессии, решающего дерева, случайного леса, LightGBM и XGBoost, но они показали результаты хуже CatBoost.\n",
    "\n",
    "Изначально при обучении модели на выборке с дисбалансом классов (отрицательных ответов в 4 раза больше положительных) модель случайного леса показала лучшее значение F1-меры - `0.6213`.\n",
    "\n",
    "После балансировки классов техникой увеличения / уменьшения выборки, значение метрики f1 у случайного леса стало только хуже. А вот CatBoost показал себя хорошо, увеличив значение с `0.5918` до `0.6185`. \n",
    "\n",
    "F1-меру удалось поднять благодаря изменению порога до `0.59`. Значение F1-меры увеличилось до `0.6586`.\n",
    "\n",
    "Также были построены кривые метрик: PR-кривая и ROC-кривая. Значение AUC-ROC `0.8445` говорит о том, что наша модель сильно отличается от случайной, т.к. чем график выше, тем больше значение TPR и, соответственно, лучше качество модели. \n",
    "\n",
    "На тестовой выборке модель показала себя хорошо: значение F1-меры равно `0.623`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
